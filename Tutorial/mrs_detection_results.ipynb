{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial how the features are extracted and introduces the entire data and its features:\n",
    "This are for basic understanding and trial of simple models. It doesn't show the result of the best complicated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessAudioFeat as paf\n",
    "#import keras_models as km\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=[\"Feature\",\"model\",\"Context\",\"Accuracy\",\"Recall\",\"Precision\",\"F1\"])\n",
    "df.to_csv('Results_4_Coria_S3.csv')\n",
    "df=pd.read_csv('Results_4_Coria_S3.csv',index_col=0, header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feature', 'model', 'Context', 'Accuracy', 'Recall', 'Precision', 'F1']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(pd.Series([1,1,1,1,1,1,1], index=df.columns.tolist()), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame([[1,1,1,1,1,1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>model</th>\n",
       "      <th>Context</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature model Context Accuracy Recall Precision F1\n",
       "0       1     1       1        1      1         1  1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [1,2,3]\n",
    "\n",
    "ls.insert(0, ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=[\"vggis\"]+[\"td_lstm\"]+ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=[ls[0],ls[3]]+ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[...], 1, 2, 3]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tempo loaded\n",
      "(444,) (111,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((333, 384, 2000), (111, 384, 2000), (333,), (111,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1, x_test1, y_train1, y_test1=paf.loadDataFeaures('tempo')\n",
    "x_train1.shape, x_test1.shape, y_train1.shape, y_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444,) (111,)\n",
      "Vggish loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((333, 138, 128), (111, 138, 128), (333,), (111,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test=paf.loadDataFeaures('vggish')\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333,) (84,)\n"
     ]
    }
   ],
   "source": [
    "x_train11, x_val,y_train11,y_val=paf.split_Data(x_train, y_train)\n",
    "\n",
    "x_train12, x_val1,y_train12,y_val1=paf.split_Data(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333,) (84,)\n",
      "(333,) (84,)\n"
     ]
    }
   ],
   "source": [
    "x_train111, x_val11,y_train111,y_val11=paf.split_Data(x_train1, y_train1)\n",
    "\n",
    "x_train112, x_val112,y_train112,y_val112=paf.split_Data(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics used to compute recall, precision, F1 and accuracy of the methods. Thay are also provided in the libarary of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score,precision_score,f1_score\n",
    "def rec_pre_f1_MRS(y_test,pred_test):\n",
    "    rec=recall_score(y_test.tolist(),pred_test,average=None)\n",
    "    pre=precision_score(y_test.tolist(),pred_test,average=None)\n",
    "    f1=f1_score(y_test,pred_test,average=None)\n",
    "    return rec,pre,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_pre_f1(y_test,pred_test,avg='micro'):\n",
    "\n",
    "    rec=recall_score(y_test,pred_test,average=avg,pos_label=1,labels=[1])\n",
    "\n",
    "    prec=precision_score(y_test,pred_test,average=avg,pos_label=1,labels=[1])\n",
    "\n",
    "    f1=f1_score(y_test,pred_test,average=avg,pos_label=1,labels=[1])\n",
    "    return rec,prec,f1\n",
    "\n",
    "def rec_pre_f1_MRS(y_test,pred_test):\n",
    "    rec=recall_score(y_test.tolist(),pred_test,average=None)\n",
    "    pre=precision_score(y_test.tolist(),pred_test,average=None)\n",
    "    f1=f1_score(y_test,pred_test,average=None)\n",
    "    return rec,pre,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_Df=pd.read_csv(\"Scene_Dataset_Normalized.csv\")\n",
    "sceneLabels=dataset_Df.MRS.tolist()\n",
    "labels=[i if i==0 else 1 for i in sceneLabels]\n",
    "pos_mrs=[i for i in range(len(sceneLabels)) if sceneLabels[i]!=0]\n",
    "mfcc,melspectogram,tempo,spec_centroids,vggFeat=paf.loadAllFeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mfccA,melspectogramA,tempoA,spec_centroidsA,vggFeatA=loadAugmentedData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(mfcc))\n",
    "x1, x2, y1, y2, idx1, idx2 = train_test_split(mfcc, labels, indices, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[39:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "posMRS_tr=[]\n",
    "for i in idx1:\n",
    "    if labels[i]==1:\n",
    "        posMRS_tr.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[382, 109, 333, 341, 103, 167, 416, 271, 209, 360, 37, 265, 146, 129, 336, 183, 233, 136, 197, 258, 432, 133, 186, 142, 240, 338, 41, 27, 347, 230, 288, 40, 375, 216, 295, 251, 309, 259, 53, 1, 366, 264, 166, 426, 54, 440, 344, 313, 413, 257, 130, 214, 443, 348] 54\n"
     ]
    }
   ],
   "source": [
    "print(posMRS_tr,len(posMRS_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio data simple augmentation techniques used to augment only the MRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulateNoiseInjection(data, noise_factor):\n",
    "    noise = np.random.randn(len(data))\n",
    "    augmented_data = data + noise_factor * noise\n",
    "    # Cast back to same data type\n",
    "    augmented_data = augmented_data.astype(type(data[0]))\n",
    "    return augmented_data\n",
    "\n",
    "def manipulateShiftingTime(data, sampling_rate, shift_max, shift_direction):\n",
    "    shift = np.random.randint(sampling_rate * shift_max)\n",
    "    if shift_direction == 'right':\n",
    "        shift = -shift\n",
    "    elif shift_direction == 'both':\n",
    "        direction = np.random.randint(0, 2)\n",
    "        if direction == 1:\n",
    "            shift = -shift    \n",
    "    augmented_data = np.roll(data, shift)\n",
    "    # Set to silence for heading/ tailing\n",
    "    if shift > 0:\n",
    "        augmented_data[:shift] = 0\n",
    "    else:\n",
    "        augmented_data[shift:] = 0\n",
    "    return augmented_data\n",
    "\n",
    "def manipulateChangingPitch(data, sampling_rate, pitch_factor):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "def manipulateChangingSpeed(data, speed_factor):\n",
    "    return librosa.effects.time_stretch(data, speed_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioDir=\"/vol/work3/berhe/MRS_Detection/SceneAudio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentMRS(posMRS_training)\n",
    "    audioDir=\"/vol/work3/berhe/MRS_Detection/SceneAudio/\"\n",
    "    for i in posMRS_training:\n",
    "        #print(\"Scene :{}\".format(i+1))\n",
    "        sys.stdout.write('Scene %s\\r' % str(i+1))\n",
    "        sys.stdout.flush()\n",
    "        audioFile=audioDir+\"Scene_\"+str(i+1)+\".wav\"\n",
    "        y, sr=librosa.load(audioFile)\n",
    "        augmented_data=manipulateNoiseInjection(y,noise_factor=0.005)\n",
    "        soundfile.write(audioDir+\"AugmentedMRS/Noise_Scene_\"+str(i+1)+\".wav\", augmented_data, sr)\n",
    "        augmented_data=manipulateChangingSpeed(y,speed_factor=2)\n",
    "        soundfile.write(audioDir+\"AugmentedMRS/Speed_Scene_\"+str(i+1)+\".wav\", augmented_data, sr)\n",
    "        augmented_data=manipulateShiftingTime(y,sampling_rate=sr, shift_max=30, shift_direction=\"left\")\n",
    "        soundfile.write(audioDir+\"AugmentedMRS/ShiftLeft_Scene_\"+str(i+1)+\".wav\", augmented_data, sr)\n",
    "        augmented_data=manipulateChangingPitch(y,sampling_rate=sr,pitch_factor=5)\n",
    "        soundfile.write(audioDir+\"AugmentedMRS/Pitch_Scene_\"+str(i+1)+\".wav\", augmented_data, sr)\n",
    "    print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLabels=[]\n",
    "for i in range(idx2.shape[0]):\n",
    "    testLabels.append(labels[idx2[i]])\n",
    "testLabels=np.array(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444,) (111,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test=km.processDataB(vggFeat,labels,testSize=0.25)\n",
    "pickle.dump(x_train,open(\"Data/TrainingData/vggish_q_x_training\",\"wb\"))\n",
    "pickle.dump(y_train,open(\"Data/TrainingData/vggish_q_y_train\",\"wb\"))\n",
    "pickle.dump(x_test,open(\"Data/TestData/vggish_q_x_test\",\"wb\"))\n",
    "pickle.dump(y_test,open(\"Data/TestData/vggish_q_y_test\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 111)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "paf.generateSameLength?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_sl=paf.generateSameLength(mfcc,)\n",
    "mel_sl=paf.generateSameLength(melspectogram)\n",
    "mfcc_aug,binaryLabels=paf.augmentMRS_data(pos_mrs,mfcc,labels)\n",
    "mfcc_r=paf.augment_reshape(mfcc_aug)\n",
    "mel_aug,binaryLabels=paf.augmentMRS_data(pos_mrs,melspectogram,labels)\n",
    "mel_r=paf.augment_reshape(mel_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sameLengthVgg(vggfeat):\n",
    "    sceneLength=[i.shape[0] for i in vggfeat]\n",
    "    minLength=min(sceneLength)\n",
    "    print(minLength)\n",
    "    reshapedData=[]\n",
    "    for i in vggfeat:\n",
    "        reshapedData.append(i[i.shape[0]-minLength:i.shape[0],:])\n",
    "    reshapedData=np.array(reshapedData)\n",
    "    return reshapedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_reshapeVgg(audioData,avgLength=138):\n",
    "    augmentZero=np.zeros(audioData[0].shape[1])\n",
    "    sceneLength=[i.shape[0] for i in audioData]\n",
    "    minLength=min(sceneLength)\n",
    "    reshapedData=[]\n",
    "    for i in audioData:\n",
    "        dataArray=i\n",
    "        if dataArray.shape[0] < avgLength:\n",
    "            for j in range(dataArray.shape[0]+1,avgLength+1):\n",
    "                dataArray=np.concatenate((dataArray,augmentZero[None,:]),axis=0)\n",
    "            print(dataArray.shape,dataArray[::-1].shape)\n",
    "            reshapedData.append(dataArray)\n",
    "        else:\n",
    "            print(\"here\",i[i.shape[0]-avgLength:,:].shape)\n",
    "            reshapedData.append(i[i.shape[0]-avgLength:,:])\n",
    "    reshapedData=np.array(reshapedData)\n",
    "    return reshapedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "vggFeat_sl_a=sameLengthVgg(vggFeatA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 13, 128)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggFeat_sl_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(660, 20, 2000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 128)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggFeat[0][vggFeat[0].shape[0]-20:vggFeat[0].shape[0],:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((444, 1, 128), (92, 128), (20, 3112))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggFeat_sl.shape,vggFeat[0].shape,mfcc[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC features results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(660,) (218,)\n",
      "(442, 20, 2000) (218, 20, 2000)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test=km.processDataB(mfcc_r,binaryLabels,testSize=0.33)\n",
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(660,) (165,)\n",
      "(165, 20, 2000) (495, 20, 2000)\n",
      "WARNING:tensorflow:From /people/berhe/anaconda3/envs/audio_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "(165, 20, 2000, 1) (165,)\n",
      "WARNING:tensorflow:From /people/berhe/anaconda3/envs/audio_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 495 samples, validate on 165 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 3.3711 - accuracy: 0.4949 - val_loss: 0.7743 - val_accuracy: 0.4727\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.77431, saving model to weights.best.cnn.hdf5\n",
      "Epoch 2/5\n",
      " - 7s - loss: 1.1380 - accuracy: 0.5131 - val_loss: 1.0528 - val_accuracy: 0.4364\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.77431\n",
      "Epoch 3/5\n",
      " - 7s - loss: 0.7981 - accuracy: 0.4970 - val_loss: 0.7600 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.77431 to 0.75996, saving model to weights.best.cnn.hdf5\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.7699 - accuracy: 0.5293 - val_loss: 0.9521 - val_accuracy: 0.4303\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.75996\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.7100 - accuracy: 0.5717 - val_loss: 0.7926 - val_accuracy: 0.4303\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.75996\n",
      "Training completed in time:  0:00:38.008737\n",
      "Training Accuracy 0.45858585834503174  \n",
      "Testing Accuracy 0.43030303716659546 \n",
      "0.7432432432432432 0.4230769230769231 0.5392156862745098\n"
     ]
    }
   ],
   "source": [
    "pred_test_r, y_test=km.trainModel(mfcc_r,binaryLabels,epochs=5,batch_size=64,model_type='cnn')\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test,pred_test_r)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(660,) (165,)\n",
      "Build LSTM RNN model ...\n",
      "(165, 20, 2000) (165,)\n",
      "Train on 495 samples, validate on 165 samples\n",
      "Epoch 1/5\n",
      " - 6s - loss: 0.7040 - accuracy: 0.5535 - val_loss: 0.6713 - val_accuracy: 0.5879\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67134, saving model to weights.best.lstm.hdf5\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.4642 - accuracy: 0.8141 - val_loss: 0.6665 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67134 to 0.66654, saving model to weights.best.lstm.hdf5\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.3359 - accuracy: 0.9172 - val_loss: 0.7295 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.66654\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.2373 - accuracy: 0.9212 - val_loss: 0.7885 - val_accuracy: 0.6242\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.66654\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.2102 - accuracy: 0.9293 - val_loss: 0.8555 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.66654\n",
      "Training completed in time:  0:00:26.349687\n",
      "Training Accuracy 0.9353535175323486  \n",
      "Testing Accuracy 0.6363636255264282 \n",
      "0.4594594594594595 0.6296296296296297 0.53125\n"
     ]
    }
   ],
   "source": [
    "pred_test_r, y_test=km.trainModel(mfcc_r,binaryLabels,epochs=5,batch_size=64,model_type='lstm')\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test,pred_test_r)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444,) (111,)\n",
      "(111, 20, 61) (333, 20, 61)\n",
      "(111, 20, 61, 1) (111,)\n",
      "Train on 333 samples, validate on 111 samples\n",
      "Epoch 1/5\n",
      " - 1s - loss: 5.4456 - accuracy: 0.5736 - val_loss: 2.5085 - val_accuracy: 0.8378\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.50853, saving model to weights.best.cnn.hdf5\n",
      "Epoch 2/5\n",
      " - 0s - loss: 3.7218 - accuracy: 0.8378 - val_loss: 1.7968 - val_accuracy: 0.8378\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.50853 to 1.79685, saving model to weights.best.cnn.hdf5\n",
      "Epoch 3/5\n",
      " - 0s - loss: 2.0393 - accuracy: 0.8288 - val_loss: 0.6102 - val_accuracy: 0.8378\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.79685 to 0.61018, saving model to weights.best.cnn.hdf5\n",
      "Epoch 4/5\n",
      " - 0s - loss: 1.1147 - accuracy: 0.6757 - val_loss: 0.5360 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61018 to 0.53602, saving model to weights.best.cnn.hdf5\n",
      "Epoch 5/5\n",
      " - 0s - loss: 0.7368 - accuracy: 0.7177 - val_loss: 0.4381 - val_accuracy: 0.8378\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53602 to 0.43807, saving model to weights.best.cnn.hdf5\n",
      "Training completed in time:  0:00:03.933593\n",
      "Training Accuracy 0.8348348140716553  \n",
      "Testing Accuracy 0.837837815284729 \n",
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_test_s, y_test_s=km.trainModel(mfcc_sl,labels,epochs=5,batch_size=64,model_type='cnn')\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test_s,pred_test_s)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.] [0.8707483 0.       ] [0.93090909 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(rec,prec,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444,) (147,)\n",
      "Build LSTM RNN model ...\n",
      "(147, 20, 61) (147,)\n",
      "Train on 297 samples, validate on 147 samples\n",
      "Epoch 1/5\n",
      " - 2s - loss: 0.5456 - accuracy: 0.7811 - val_loss: 0.4000 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40004, saving model to weights.best.lstm.hdf5\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.4558 - accuracy: 0.8215 - val_loss: 0.3945 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40004 to 0.39445, saving model to weights.best.lstm.hdf5\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.4251 - accuracy: 0.8249 - val_loss: 0.4055 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.39445\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.3950 - accuracy: 0.8283 - val_loss: 0.3998 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.39445\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.3606 - accuracy: 0.8316 - val_loss: 0.3935 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.39445 to 0.39354, saving model to weights.best.lstm.hdf5\n",
      "Training completed in time:  0:00:09.060175\n",
      "Training Accuracy 0.8316498398780823  \n",
      "Testing Accuracy 0.8707482814788818 \n",
      "[1. 0.] [0.8707483 0.       ] [0.93090909 0.        ]\n"
     ]
    }
   ],
   "source": [
    "pred_test_s, y_test_s=km.trainModel(mfcc_sl,labels,epochs=5,batch_size=64,model_type='lstm')\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test_s,pred_test_s)\n",
    "print(rec[1],prec[1],f1[1])\n",
    "#print(rec,prec,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.81:\n",
      "[1. 0.] [0.80952381 0.        ] [0.89473684 0.        ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "nsamples, nx, ny = mfcc_sl.shape\n",
    "d2_train_dataset = mfcc_sl.reshape((nsamples,nx*ny))\n",
    "\n",
    "pred_test_svm_sl, y_test_svm=km.predictSVM(d2_train_dataset,labels)\n",
    "y_test_svm=np.array(y_test_svm)\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test_svm,pred_test_svm_sl)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.638:\n",
      "0.3978494623655914 0.4157303370786517 0.4065934065934066\n"
     ]
    }
   ],
   "source": [
    "nsamples, nx, ny = mfcc_r.shape\n",
    "d2_train_dataset = mfcc_r.reshape((nsamples,nx*ny))\n",
    "\n",
    "pred_test_svm_r, y_test_svm=km.predictSVM(d2_train_dataset,binaryLabels)\n",
    "y_test_svm=np.array(y_test_svm)\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test_svm,pred_test_r)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MelSpectogram Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444,) (147,)\n",
      "(147, 128, 61, 1) (147,)\n",
      "Train on 297 samples, validate on 147 samples\n",
      "Epoch 1/5\n",
      " - 2s - loss: 0.6362 - accuracy: 0.6835 - val_loss: 0.6558 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65577, saving model to weights.best.cnn.hdf5\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.6114 - accuracy: 0.8215 - val_loss: 0.6699 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.65577\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.5909 - accuracy: 0.8215 - val_loss: 0.6244 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65577 to 0.62439, saving model to weights.best.cnn.hdf5\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.5564 - accuracy: 0.8215 - val_loss: 0.5809 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.62439 to 0.58092, saving model to weights.best.cnn.hdf5\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.5442 - accuracy: 0.8215 - val_loss: 0.5545 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.58092 to 0.55452, saving model to weights.best.cnn.hdf5\n",
      "Training completed in time:  0:00:09.725472\n",
      "Training Accuracy 0.8215488195419312  \n",
      "Testing Accuracy 0.8707482814788818 \n",
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_test_s_mel, y_test_s_mel=km.trainModel(mel_sl,labels,epochs=5,batch_size=64,model_type='cnn')\n",
    "y_test_s_mel=np.array(y_test_s_mel)\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test_s_mel,pred_test_s_mel)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444,) (147,)\n",
      "Build LSTM RNN model ...\n",
      "(147, 128, 61) (147,)\n",
      "Train on 297 samples, validate on 147 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 0.6739 - accuracy: 0.7609 - val_loss: 0.5906 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59063, saving model to weights.best.lstm.hdf5\n",
      "Epoch 2/5\n",
      " - 6s - loss: 0.5417 - accuracy: 0.8215 - val_loss: 0.3848 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.59063 to 0.38484, saving model to weights.best.lstm.hdf5\n",
      "Epoch 3/5\n",
      " - 6s - loss: 0.4759 - accuracy: 0.8249 - val_loss: 0.4089 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.38484\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.4795 - accuracy: 0.8182 - val_loss: 0.3890 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.38484\n",
      "Epoch 5/5\n",
      " - 6s - loss: 0.4662 - accuracy: 0.8249 - val_loss: 0.3921 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38484\n",
      "Training completed in time:  0:00:35.020170\n",
      "Training Accuracy 0.8249158263206482  \n",
      "Testing Accuracy 0.8707482814788818 \n",
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_test_s_mel, y_test_s_mel=km.trainModel(mel_sl,labels,epochs=5,batch_size=64,model_type='lstm')\n",
    "y_test_s_mel=np.array(y_test_s_mel)\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test_s_mel,pred_test_s_mel)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(660,) (218,)\n",
      "(218, 128, 2000, 1) (218,)\n",
      "Train on 442 samples, validate on 218 samples\n",
      "Epoch 1/5\n",
      " - 63s - loss: 0.6979 - accuracy: 0.5204 - val_loss: 0.6920 - val_accuracy: 0.5229\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69202, saving model to weights.best.cnn.hdf5\n",
      "Epoch 2/5\n",
      " - 61s - loss: 0.6901 - accuracy: 0.5543 - val_loss: 0.6981 - val_accuracy: 0.5229\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.69202\n",
      "Epoch 3/5\n",
      " - 63s - loss: 0.6892 - accuracy: 0.5566 - val_loss: 0.6983 - val_accuracy: 0.5321\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69202\n",
      "Epoch 4/5\n",
      " - 65s - loss: 0.6914 - accuracy: 0.5566 - val_loss: 0.6932 - val_accuracy: 0.5275\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.69202\n",
      "Epoch 5/5\n",
      " - 71s - loss: 0.6928 - accuracy: 0.5204 - val_loss: 0.7107 - val_accuracy: 0.5183\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.69202\n",
      "Training completed in time:  0:05:29.384793\n",
      "Training Accuracy 0.5633484125137329  \n",
      "Testing Accuracy 0.5183486342430115 \n",
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_test_r_mel, y_test_r_mel=km.trainModel(mel_r,binaryLabels,epochs=5,batch_size=64,model_type='cnn')\n",
    "#y_test_s_mel=np.array(y_test_s_mel)\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test_r_mel,pred_test_r_mel)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(660,) (218,)\n",
      "Build LSTM RNN model ...\n",
      "(218, 128, 2000) (218,)\n",
      "Train on 442 samples, validate on 218 samples\n",
      "Epoch 1/5\n",
      " - 27s - loss: 0.6912 - accuracy: 0.5656 - val_loss: 0.6736 - val_accuracy: 0.5780\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67360, saving model to weights.best.lstm.hdf5\n",
      "Epoch 2/5\n",
      " - 26s - loss: 0.6182 - accuracy: 0.6584 - val_loss: 0.7442 - val_accuracy: 0.5459\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.67360\n",
      "Epoch 3/5\n",
      " - 25s - loss: 0.5364 - accuracy: 0.7330 - val_loss: 0.7547 - val_accuracy: 0.5275\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.67360\n",
      "Epoch 4/5\n",
      " - 25s - loss: 0.4642 - accuracy: 0.7851 - val_loss: 0.8123 - val_accuracy: 0.5826\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.67360\n",
      "Epoch 5/5\n",
      " - 24s - loss: 0.3923 - accuracy: 0.8281 - val_loss: 0.9413 - val_accuracy: 0.5826\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.67360\n",
      "Training completed in time:  0:02:14.719580\n",
      "Training Accuracy 0.8823529481887817  \n",
      "Testing Accuracy 0.5825688242912292 \n",
      "0.4838709677419355 0.5113636363636364 0.4972375690607735\n"
     ]
    }
   ],
   "source": [
    "pred_test_r_mel, y_test_r_mel=km.trainModel(mel_r,binaryLabels,epochs=5,batch_size=64,model_type='lstm')\n",
    "#y_test_s_mel=np.array(y_test_s_mel)\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test_r_mel,pred_test_r_mel)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.81:\n",
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "nsamples, nx, ny = mel_sl.shape\n",
    "d2_train_dataset = mel_sl.reshape((nsamples,nx*ny))\n",
    "\n",
    "pred_test_svm_sl_mel, y_test_svm=km.predictSVM(d2_train_dataset,labels)\n",
    "y_test_svm=np.array(y_test_svm)\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test_svm,pred_test_svm_sl_mel)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.624:\n",
      "0.3010752688172043 0.6222222222222222 0.4057971014492754\n"
     ]
    }
   ],
   "source": [
    "nsamples, nx, ny = mel_r.shape\n",
    "d2_train_dataset = mel_r.reshape((nsamples,nx*ny))\n",
    "pred_test_svm_r_mel, y_test_svm_aug=km.predictSVM(d2_train_dataset,binaryLabels)\n",
    "y_test_svm=np.array(y_test_svm_aug)\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test_svm,pred_test_svm_r_mel)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3010752688172043 0.6222222222222222 0.4057971014492754\n"
     ]
    }
   ],
   "source": [
    "y_test_svm=np.array(y_test_svm_aug)\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test_svm,pred_test_svm_r_mel)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGish Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444,) (147,)\n",
      "WARNING:tensorflow:From /people/berhe/anaconda3/envs/audio_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "(147, 138, 128, 1) (147,)\n",
      "WARNING:tensorflow:From /people/berhe/anaconda3/envs/audio_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 297 samples, validate on 147 samples\n",
      "Epoch 1/5\n",
      " - 3s - loss: 0.5856 - accuracy: 0.8215 - val_loss: 0.5016 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50159, saving model to weights.best.cnn.hdf5\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.4756 - accuracy: 0.8215 - val_loss: 0.4312 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50159 to 0.43124, saving model to weights.best.cnn.hdf5\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.5031 - accuracy: 0.8215 - val_loss: 0.4291 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.43124 to 0.42915, saving model to weights.best.cnn.hdf5\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.4817 - accuracy: 0.8215 - val_loss: 0.4615 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.42915\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.4784 - accuracy: 0.8215 - val_loss: 0.4815 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.42915\n",
      "Training completed in time:  0:00:14.355785\n",
      "Training Accuracy 0.8215488195419312  \n",
      "Testing Accuracy 0.8707482814788818 \n",
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_test_r, y_test=km.trainModel(vggFeat_aug,labels,epochs=5,batch_size=64,model_type='cnn')\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test,pred_test_r)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444,) (147,)\n",
      "Build LSTM RNN model ...\n",
      "(147, 128, 138) (147,)\n",
      "Train on 297 samples, validate on 147 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 0.5283 - accuracy: 0.7744 - val_loss: 0.4130 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41303, saving model to weights.best.lstm.hdf5\n",
      "Epoch 2/5\n",
      " - 6s - loss: 0.4751 - accuracy: 0.8215 - val_loss: 0.4175 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.41303\n",
      "Epoch 3/5\n",
      " - 6s - loss: 0.4547 - accuracy: 0.8215 - val_loss: 0.3941 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.41303 to 0.39412, saving model to weights.best.lstm.hdf5\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.4457 - accuracy: 0.8215 - val_loss: 0.4004 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.39412\n",
      "Epoch 5/5\n",
      " - 6s - loss: 0.4450 - accuracy: 0.8215 - val_loss: 0.4177 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.39412\n",
      "Training completed in time:  0:00:35.010143\n",
      "Training Accuracy 0.8215488195419312  \n",
      "Testing Accuracy 0.8707482814788818 \n",
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_test_r, y_test=km.trainModel(vggFeat_augT,labels,epochs=5,batch_size=64,model_type='lstm')\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test,pred_test_r)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444,) (147,)\n",
      "(147, 128, 138, 1) (147,)\n",
      "Train on 297 samples, validate on 147 samples\n",
      "Epoch 1/5\n",
      " - 3s - loss: 0.5859 - accuracy: 0.8215 - val_loss: 0.4995 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.49955, saving model to weights.best.cnn.hdf5\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.4798 - accuracy: 0.8215 - val_loss: 0.4306 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.49955 to 0.43063, saving model to weights.best.cnn.hdf5\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.4954 - accuracy: 0.8215 - val_loss: 0.4387 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.43063\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.4783 - accuracy: 0.8215 - val_loss: 0.4720 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.43063\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.4780 - accuracy: 0.8215 - val_loss: 0.4814 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.43063\n",
      "Training completed in time:  0:00:14.630325\n",
      "Training Accuracy 0.8215488195419312  \n",
      "Testing Accuracy 0.8707482814788818 \n",
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_test_r, y_test=km.trainModel(vggFeat_augT,labels,epochs=5,batch_size=64,model_type='cnn')\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test,pred_test_r)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Frames VGGish\n",
    "feat=np.load(\"5_frames.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444,) (111,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test=km.processDataB(feat,labels,testSize=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 62, 128)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build LSTM RNN model ...\n",
      "(333, 62, 128) (111, 62, 128)\n",
      "Train on 333 samples, validate on 111 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 0.5634 - accuracy: 0.7057 - val_loss: 0.4760 - val_accuracy: 0.8378\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.4565 - accuracy: 0.8378 - val_loss: 0.4435 - val_accuracy: 0.8378\n",
      "Epoch 3/5\n",
      " - 3s - loss: 0.4481 - accuracy: 0.8378 - val_loss: 0.4445 - val_accuracy: 0.8378\n",
      "Epoch 4/5\n",
      " - 6s - loss: 0.4525 - accuracy: 0.8378 - val_loss: 0.4441 - val_accuracy: 0.8378\n",
      "Epoch 5/5\n",
      " - 7s - loss: 0.4444 - accuracy: 0.8378 - val_loss: 0.4433 - val_accuracy: 0.8378\n",
      "Training completed in time:  0:00:37.681847\n",
      "Training Accuracy 0.837837815284729  \n",
      "Testing Accuracy 0.837837815284729 \n",
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_test_r, y_test=km.trainModel_splitedData(x_train, x_test, y_train, y_test,epochs=5,batch_size=64,model_type='lstm')\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test,pred_test_r)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 62, 128) (333, 62, 128)\n",
      "(333, 62, 128, 1) (111, 62, 128, 1)\n",
      "Train on 333 samples, validate on 111 samples\n",
      "Epoch 1/5\n",
      " - 4s - loss: 25.3319 - accuracy: 0.5676 - val_loss: 10.7397 - val_accuracy: 0.8378\n",
      "Epoch 2/5\n",
      " - 1s - loss: 17.4319 - accuracy: 0.8378 - val_loss: 6.3996 - val_accuracy: 0.8378\n",
      "Epoch 3/5\n",
      " - 1s - loss: 7.9188 - accuracy: 0.8378 - val_loss: 6.5741 - val_accuracy: 0.1622\n",
      "Epoch 4/5\n",
      " - 1s - loss: 3.2765 - accuracy: 0.4474 - val_loss: 0.9946 - val_accuracy: 0.8378\n",
      "Epoch 5/5\n",
      " - 2s - loss: 2.7601 - accuracy: 0.8378 - val_loss: 0.4925 - val_accuracy: 0.8378\n",
      "Training completed in time:  0:00:14.955924\n",
      "Training Accuracy 0.837837815284729  \n",
      "Testing Accuracy 0.837837815284729 \n",
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_test_r, y_test=km.trainModel_splitedData(x_train, x_test, y_train, y_test,epochs=5,batch_size=64,model_type='cnn')\n",
    "rec,prec,f1=rec_pre_f1_MRS(y_test,pred_test_r)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.838:\n"
     ]
    }
   ],
   "source": [
    "x_train1=np.average(x_train,axis=1)\n",
    "x_test1=np.average(x_test,axis=1)\n",
    "pred_test,y_test=km.predictSVMSplit(x_train1, x_test1, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "rec,prec,f1=rec_pre_f1_MRS(y_test,pred_test)\n",
    "print(rec[1],prec[1],f1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 128)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 128)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
